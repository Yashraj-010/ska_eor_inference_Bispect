{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Ian Hothi\n",
    "# Date: Feb 2025\n",
    "\n",
    "import numpy as np\n",
    "#For Power Spectrum Calculations \n",
    "import tools21cm as t2c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data has been simulated using 21cmFast. The XY plane has an extent of 250Mpc, with 256 pixels on each side. The line-of-sight (redshift) has been simulated to be between z = 8.82 (144.60 MHz) and z = 9.33 (137.46 MHz), comprising 128 frequency channels. The three parameters chosen to be changed are the virial temperature, maximum bubble size, and the ionising efficiency parameter—these were all found to have the strongest impact on the signal. \n",
    "\n",
    "These are the parameter variations (fiducial value $\\pm$ change):\n",
    "\n",
    "- $T_{Vir}$: $50000\\pm 5000$\n",
    "- $R_{Max}$: $15\\pm 5 Mpc$\n",
    "- $\\zeta$: $30\\pm 5$,\n",
    "400 simulations were run for each parameter value, which will be used for the derivatives. In the loaded files, there will be two files for each parameter, one corresponding to the plus value - for example, for $T_{Vir}$ tue value would be 50000 + 5000. Whereas the minus value would be 50000 - 5000.\n",
    "\n",
    "\n",
    "400 simulations were run with the fiducial values, this will serve to calculate the covariances of the statistics.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fisher Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Astro params\n",
    "params = ['ION_Tvir_MIN']#['ION_Tvir_MIN','R_BUBBLE_MAX','HII_EFF_FACTOR']\n",
    "nparams = len(params)\n",
    "delta_params = [pow(10,4.740362689494244)-pow(10,4.653212513775344),10,10]\n",
    "\n",
    "# Sim params\n",
    "# Lightcone dimensions\n",
    "box_dim = 256\n",
    "box_length = 200\n",
    "\n",
    "# Power spectrum params\n",
    "nbins = 15\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data and Statistics estimation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Lightcone_ION_Tvir_MIN_400_Samples_Plus.npz…\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/SKA_Chapter_simulations/Lightcone_ION_Tvir_MIN_400_Samples_Plus.npz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/h3/6k136qw97hjf1w5_0q84nnl80000gq/T/ipykernel_37810/532712727.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m# Memory‐map the huge array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmmap_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'arr_0'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mn_samp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pywst/lib/python3.7/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    415\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/SKA_Chapter_simulations/Lightcone_ION_Tvir_MIN_400_Samples_Plus.npz'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import numpy as np\n",
    "\n",
    "# Configuration\n",
    "ddir      = '/SKA_Chapter_simulations/'\n",
    "out_dir   = '/SKA_Chapter_simulations/PowerSpectra/'  # make sure this exists!\n",
    "nbins     = 15\n",
    "box_length= 400\n",
    "\n",
    "# List of (filename, output_basename) pairs\n",
    "jobs = [\n",
    "    ('Lightcone_ION_Tvir_MIN_400_Samples_Plus.npz',     'PS_param_1_plus'),\n",
    "    ('Lightcone_ION_Tvir_MIN_400_Samples_Minus.npz',    'PS_param_1_minus'),\n",
    "    ('Lightcone_R_BUBBLE_MAX_400_Samples_Plus.npz',     'PS_param_2_plus'),\n",
    "    ('Lightcone_R_BUBBLE_MAX_400_Samples_Minus.npz',    'PS_param_2_minus'),\n",
    "    ('Lightcone_HII_EFF_FACTOR_400_Samples_Plus.npz',   'PS_param_3_plus'),\n",
    "    ('Lightcone_HII_EFF_FACTOR_400_Samples_Minus.npz',  'PS_param_3_minus'),\n",
    "    ('Window_Functions/Noiseless/Lightcone_FID_400_Samples.npz', 'PS_fid'),\n",
    "]\n",
    "\n",
    "for fname, out_base in jobs:\n",
    "    path = os.path.join(ddir, fname)\n",
    "    print(f'Processing {fname}…')\n",
    "    \n",
    "    # Memory‐map the huge array\n",
    "    data = np.load(path, mmap_mode='r')['arr_0']\n",
    "    n_samp = data.shape[0]\n",
    "    \n",
    "    # Prepare output container\n",
    "    PS  = np.zeros((n_samp, nbins), dtype=np.float32)\n",
    "    ks  = None\n",
    "    \n",
    "    # Loop over each sample\n",
    "    for i in range(n_samp):\n",
    "        PS[i], ks = t2c.power_spectrum_1d(\n",
    "            data[i],\n",
    "            kbins=nbins,\n",
    "            box_dims=box_length\n",
    "        )\n",
    "        if i and i % 50 == 0:\n",
    "            print(f'  … {i}/{n_samp} done')\n",
    "    \n",
    "    # Save just the power spectra + k‐bin centers\n",
    "    out_path = os.path.join(out_dir, out_base + f'_{nbins}bins.npz')\n",
    "    np.savez_compressed(out_path, PS=PS, ks=ks)\n",
    "    print(f'  Saved → {out_path}')\n",
    "    \n",
    "    # Teardown to free memory\n",
    "    del data, PS\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "# where you dumped the .npz outputs\n",
    "stat_dir = '/SKA_Chapter_simulations/PowerSpectra/'\n",
    "\n",
    "# grab all the 15-bin runs\n",
    "files = glob.glob(os.path.join(stat_dir, '*_15bins.npz'))\n",
    "\n",
    "# container dict: keys will be e.g. 'PS_param_1_plus', 'PS_fid', etc.\n",
    "PS_data = {}\n",
    "\n",
    "for fpath in files:\n",
    "    # derive a clean name from the filename\n",
    "    basename = os.path.basename(fpath).replace('_15bins.npz','')\n",
    "    \n",
    "    # load just once\n",
    "    with np.load(fpath) as dd:\n",
    "        PS   = dd['PS']    # shape (n_samples, nbins)\n",
    "        ks   = dd['ks']    # shape (nbins,)\n",
    "    \n",
    "    PS_data[basename] = {\n",
    "        'PS':  PS,\n",
    "        'ks':  ks,\n",
    "    }\n",
    "\n",
    "# now you can refer to, e.g. PS_data['PS_param_1_plus']['PS'] \n",
    "# and PS_data['PS_param_1_plus']['ks'] etc.\n",
    "\n",
    "# Example: check shapes\n",
    "for name, dat in PS_data.items():\n",
    "    print(f\"{name:25s} → PS {dat['PS'].shape},  ks {dat['ks'].shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fisher Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Under the assumption that the likelihood is a multivariate Gaussian (mean vectors are sufficient information for the covariance matrix), the Fisher matrix is defined as:\n",
    "\n",
    "$$F^\\theta_{ij} = \\frac{\\partial \\textbf{S}}{\\partial\\theta_i} \\mathbf{\\Sigma}^{-1} \\frac{\\partial \\textbf{S}}{\\partial\\theta_j},$$\n",
    "\n",
    "where  $\\frac{\\partial \\textbf{S}}{\\partial\\theta_i}$ is the change in statistic S under a change in paramrter i of $\\partial\\theta_j$. Here, $\\mathbf{\\Sigma}$ is the the covariance matrix, given my the fiducial simulation set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us first calculate $\\frac{\\partial \\textbf{S}}{\\partial\\theta_i}$ for out three astrophysical parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 1) Pull the PS arrays out of your PS_data dict\n",
    "PS1p = PS_data['PS_param_1_plus']['PS']\n",
    "PS1m = PS_data['PS_param_1_minus']['PS']\n",
    "\n",
    "PS2p = PS_data['PS_param_2_plus']['PS']\n",
    "PS2m = PS_data['PS_param_2_minus']['PS']\n",
    "\n",
    "PS3p = PS_data['PS_param_3_plus']['PS']\n",
    "PS3m = PS_data['PS_param_3_minus']['PS']\n",
    "\n",
    "ks   = PS_data['PS_param_1_plus']['ks']\n",
    "\n",
    "# 3) Compute the finite‐difference derivatives for each k‐bin & sample\n",
    "dPS1 = (PS1p - PS1m) / delta_params[0]\n",
    "dPS2 = (PS2p - PS2m) / delta_params[1]\n",
    "dPS3 = (PS3p - PS3m) / delta_params[2]\n",
    "\n",
    "nparams  = 3\n",
    "nsamples = PS1p.shape[0]\n",
    "nbins    = PS1p.shape[1]\n",
    "\n",
    "PS_derivs = np.zeros((nparams, nsamples, nbins))\n",
    "PS_derivs[0] = dPS1\n",
    "PS_derivs[1] = dPS2\n",
    "PS_derivs[2] = dPS3\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us whiten the data to get rid of any order of magnitude issues that may arise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Whitening step ##\n",
    "PS_fid = PS_data['PS_fid']['PS'] \n",
    "\n",
    "std_fid = np.std(PS_fid,axis=0)\n",
    "white_fid = PS_fid/std_fid\n",
    "#The covariance\n",
    "covariance = np.cov(white_fid,rowvar=False)\n",
    "# Whitening the derivatives\n",
    "PS_derivs_white = PS_derivs.reshape((nparams,max_samples,-1))/std_fid\n",
    "\n",
    "# To check the condition of the covariance:\n",
    "print(('Condition Number: 10^%.3f')%(np.log10(np.linalg.cond(covariance))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now calculate the Fisher Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising Fishers \n",
    "PS_Fisher = np.zeros((len(samples),nparams,nparams))\n",
    "PS_Fisher_Inv = np.zeros((len(samples),nparams,nparams))\n",
    "\n",
    "# How many samples to use\n",
    "max_samples = len(PS_derivs_white[0])\n",
    "samples = np.arange(5,max_samples+50,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the Fisher matrix for a given sample of derivatives \n",
    "for k,sample_size in enumerate(samples):\n",
    "    deriv_sample = np.mean(derivatives_white[:,:sample_size,:],axis=1)\n",
    "    F_ij = np.zeros((nparams,nparams))\n",
    "    for i in range(nparams):\n",
    "        for j in range(nparams):\n",
    "            parm_i_ps = (deriv_sample)[i]\n",
    "            parm_j_ps = (deriv_sample)[j]        \n",
    "            FIJ = np.dot(parm_i_ps, np.dot(np.linalg.inv(covariance),parm_j_ps))\n",
    "            F_ij[i,j] = FIJ\n",
    "    F_ij_inv = np.linalg.inv(F_ij)  \n",
    "    PS_Fisher[k,:,:]= F_ij\n",
    "    PS_Fisher_Inv[k,:,:] = F_ij_inv\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is to be explicit, but we can just put this all into a function as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fisher(derivatives,fiducial,nparams):\n",
    "    \"\"\" Calculates the fisher matrix for different number of derivative samples. This function also \n",
    "        plots the 'identity' matrix derived for multiplying the covariance by its inverse - we also \n",
    "        include a histogram of this 'identity' matrix to see the zero-error.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    derivatives : numpy.array\n",
    "        An array containing the derivatives of a given statistic, with dimensions of \n",
    "        [nparams,nsamples,ncoefficients]\n",
    "    fiducial : numpy.array\n",
    "        Contains the fiducial simulation's statistic, with which we calculate the\n",
    "        covariance. It has dimensions [nsamples,ncoefficients].\n",
    "    nparams : int\n",
    "        The number of parameters for which a derivative has been calculated.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Fisher : numpy.array\n",
    "        Fisher matrix for a given number of sample used to calculate derivatives.\n",
    "        Dimensions of [len(samples), nparams, nparams]\n",
    "        \n",
    "    Fisher_Inv : numpy.array\n",
    "        Inverse of the Fisher matrix,having dimensions of [len(samples), nparams, nparams].\n",
    "    samples : numpy.array\n",
    "        Contains the number of samples of derivatives used to calculate Fisher and Fisher_Inv\n",
    "    \"\"\"\n",
    "    import numpy\n",
    "    # Maximum number of derivative samples that can be used \n",
    "    max_samples = len(derivatives[0])\n",
    "    \n",
    "    ## Whitening step ##\n",
    "    std_fid = np.std(fiducial,axis=0)\n",
    "    white_fid = fiducial/std_fid\n",
    "    #The covariance\n",
    "    covariance = np.cov(white_fid,rowvar=False)\n",
    "    # Whitening the derivatives\n",
    "    derivatives_white = derivatives.reshape((nparams,max_samples,-1))/std_fid\n",
    "    print(('Condition Number: 10^%.3f')%(np.log10(np.linalg.cond(covariance))))\n",
    "    # How many samples to use\n",
    "    samples = np.arange(5,max_samples+50,5)\n",
    "    # Initialising Fishers \n",
    "    Fisher = np.zeros((len(samples),nparams,nparams))\n",
    "    Fisher_Inv = np.zeros((len(samples),nparams,nparams))\n",
    "    \n",
    "    \n",
    "    # Checking stability of the covariance\n",
    "    plt.figure()\n",
    "    I = np.log10(abs(np.matmul(np.linalg.inv(covariance),covariance))+1e-16)\n",
    "    plt.imshow(I)\n",
    "    plt.colorbar().set_label('log$_{10} C^{-1}C$')\n",
    "    plt.figure()\n",
    "    plt.hist(I.reshape(-1),bins=100)\n",
    "    plt.xlabel('log$_{10} C^{-1}C$')\n",
    "    plt.yscale('log')\n",
    "\n",
    "    # Calculating the Fisher matrix for a given sample of derivatives \n",
    "    for k,sample_size in enumerate(samples):\n",
    "        deriv_sample = np.mean(derivatives_white[:,:sample_size,:],axis=1)\n",
    "        F_ij = np.zeros((nparams,nparams))\n",
    "        for i in range(nparams):\n",
    "            for j in range(nparams):\n",
    "                parm_i_ps = (deriv_sample)[i]\n",
    "                parm_j_ps = (deriv_sample)[j]        \n",
    "                FIJ = np.dot(parm_i_ps, np.dot(np.linalg.inv(covariance),parm_j_ps))\n",
    "                F_ij[i,j] = FIJ\n",
    "        F_ij_inv = np.linalg.inv(F_ij)  \n",
    "        Fisher[k,:,:]= F_ij\n",
    "        Fisher_Inv[k,:,:] = F_ij_inv\n",
    "    return Fisher,Fisher_Inv,samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Fisher Matrix\n",
    "PS_Fisher,PS_Fisher_Inv,samples = get_fisher(PS_derivs,PS_fid,nparams)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Using chain consumer to plot the matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fisher_Param = ['$T_{Vir}$','$R_{Max}$','$\\zeta$']\n",
    "\n",
    "from chainconsumer import ChainConsumer\n",
    "fid = [pow(10,4.7),15,30]\n",
    "\n",
    "c = ChainConsumer()\n",
    "c.add_covariance(fid,PS_Fisher_Inv[-1], parameters=Fisher_Param,shade=True,name='Power Spectrum')\n",
    "fig = c.plotter.plot(figsize='PAGE')\n",
    "fig.set_size_inches(3 + fig.get_size_inches())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Summary_Param = ['T_{Vir}','R_{Max}','\\zeta']\n",
    "\n",
    "c.add_covariance(fid,PS_Fisher_Inv[-1], parameters=Summary_Param,shade=True,name='Power Spectrum')\n",
    "\n",
    "c.plotter.plot_summary(errorbar=True,truth = fid,extra_parameter_spacing=6,show_names = False,parameters=Summary_Param)\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For comparisons, simply at covariances via 'c.add_covariance()' of the different statistics to compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
